<!DOCTYPE html>
<html lang="en">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Creating my AI assistant locally | Lucas F. Aguiar</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="For the first time I tried to break with ChatGPT and Copilot to see what I could come up with.">
    <meta name="generator" content="Hugo 0.124.1">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    

    
      

    

    

    
      <link rel="canonical" href="http://localhost:1313/post/2024.03.16/creating-my-ai-assistant-locally/">
    

    <meta property="og:title" content="Creating my AI assistant locally" />
<meta property="og:description" content="For the first time I tried to break with ChatGPT and Copilot to see what I could come up with." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/post/2024.03.16/creating-my-ai-assistant-locally/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2024-03-16T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-03-16T00:00:00+00:00" />
<meta itemprop="name" content="Creating my AI assistant locally">
<meta itemprop="description" content="For the first time I tried to break with ChatGPT and Copilot to see what I could come up with."><meta itemprop="datePublished" content="2024-03-16T00:00:00+00:00" />
<meta itemprop="dateModified" content="2024-03-16T00:00:00+00:00" />
<meta itemprop="wordCount" content="800">
<meta itemprop="keywords" content="AI,RAG,ollama,mistral,privateGPT,M2,MacBook-Air," /><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Creating my AI assistant locally"/>
<meta name="twitter:description" content="For the first time I tried to break with ChatGPT and Copilot to see what I could come up with."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  <header class="cover bg-top" style="background-image: url('https://th.bing.com/th/id/OIP.W6grzhiKRB1oTI7C569B7wAAAA?rs=1&amp;pid=ImgDetMain');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Lucas F. Aguiar
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/post/" title="Blog page">
              Blog
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/contact/contact/" title="Contact me page">
              Contact me
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/about/" title="About Me page">
              About Me
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/post/" title="Blog page">
              Blog
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/contact/" title="Contacts page">
              Contacts
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
    
    <a href="https://linkedin.com/in/lucas-fernandes-aguiar" target="_blank" rel="noopener" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <div class="f2 f1-l fw2 white-90 mb0 lh-title">Creating my AI assistant locally</div>
          
            <div class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
              For the first time I tried to break with ChatGPT and Copilot to see what I could come up with.
            </div>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Blog
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
      
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://localhost:1313/post/2024.03.16/creating-my-ai-assistant-locally/&amp;title=Creating%20my%20AI%20assistant%20locally" class="ananke-social-link linkedin no-underline" aria-label="share on LinkedIn">
        
        <span class="icon"> <svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
        
      </a>
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Creating my AI assistant locally</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2024-03-16T00:00:00Z">March 16, 2024</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>It surprised me how easy it was to build a local solution with <a href="https://ollama.com/">Ollama</a>.</p>
<h1 id="introduction">Introduction</h1>
<p>This itch to have a private solution for AI came to me after I saw that OpenAI changed their settings on the playground section and does not allow for free users to test the models. With that I went to check Gemini but it was the same thing. Both of them are costing $20/month and for me it isn&rsquo;t worth it at the moment. Because of that I went looking for private ones, since I had already seen people doing running AI solution locally. Coupled with the fact that I got a new M2 MacBook Air, I decided to test the limits.</p>
<h1 id="ollama">Ollama</h1>
<p>Ollama is the first try for me and it worked out the box. You download and run from the terminal with the command <code>ollama run llama2</code>. This command will download the model llama2 and start the program with that model already running. This specific model has around 7 billion parameters and is a little more than 3 GB in size. If you a decent connection it goes really fast. I tested it and it was surprisingly quick. Then I tested the <code>mistral</code>and <code>gemma</code>models.
The <code>mistral</code>model ran fine, but the <code>gemma</code> model did not run well and since I didn&rsquo;t have the time to check what was wrong, I just checked to see if there was a solution and sure enough, there seems to be one but I did not test it.</p>
<h1 id="privagegpt">PrivageGPT</h1>
<p>This is the second part which is a little bit harder to implement but is easy enough to implement a Retrieval-augmented generation (RAG), which basically means that you can provide the source files to be ingested by the model and provide you with a query interface for those files. So I stumbled upon the <a href="https://github.com/imartinez/privateGPT">imartinez/privateGPT</a> repository. The setup is somewhat straight forward and well document at <a href="https://docs.privategpt.dev/installation/getting-started/installation">PrivateGPT | Docs</a>.
The main problem that I had was with Poetry and Python versions to run the project. The project must be ran using the 3.11 version. But the more I tried it was always running with 3.12. This the workaround that made it work.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ brew install pyenv
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Any modern version python should do. I don&#39;t think Python 2 is required any more.</span>
</span></span><span style="display:flex;"><span>$ pyenv install 3.11.8
</span></span><span style="display:flex;"><span>$ pyenv global 3.11.8
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Add pyenv to your PATH so that you can reference python (not python3)</span>
</span></span><span style="display:flex;"><span>$ echo <span style="color:#e6db74">&#34;export PATH=\&#34;\${HOME}/.pyenv/shims:\${PATH}\&#34;&#34;</span> &gt;&gt; ~/.zshrc
</span></span><span style="display:flex;"><span>$ source ~/.zshrc
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># open a new terminal window and confirm your pyenv version is mapped to python</span>
</span></span><span style="display:flex;"><span>$ which python
</span></span><span style="display:flex;"><span>$ python --version
</span></span></code></pre></div><p>Also, see for reference: <a href="https://python-poetry.org/docs/managing-environments/#switching-between-environments">Managing environments | Documentation | Poetry - Python dependency management and packaging made easy</a></p>
<h1 id="running-privategpt">Running privateGPT</h1>
<p>To run it needs to have the <code>ollama</code> server running. This can be done in MacOS by having it open in the background, or through the command <code>ollama serve</code>.
Than, in another terminal window, run the following commands from the directory where privateGPT is. In my case I forked the repository it so I could make changes to the files with no worries.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Pull the models, the LLM and embedding</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ollama pull mistral <span style="color:#75715e"># LLM</span>
</span></span><span style="display:flex;"><span>ollama pull nomic-embed-text <span style="color:#75715e"># Embedding model</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Install dependencies</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>poetry install --extras <span style="color:#e6db74">&#34;ui llms-ollama embeddings-ollama vector-stores-qdrant&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run privateGPT</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>PGPT_PROFILES<span style="color:#f92672">=</span>ollama make run
</span></span></code></pre></div><p>The interface should be available to be viewed by opening the following address on the browser <a href="http://127.0.0.1:8001/">127.0.0.1:8001</a>.</p>
<h1 id="ingesting-files-and-queries">Ingesting files and queries</h1>
<p>I used a article from a research in biodegradable plastics for Bagheri et al. The ingesting can be seen in the image as the first line. After it is ingested i can query the file for information.</p>
<p><img alt="Ingesting a single file" src="/images/Ingesting%20files%2020240316213238.png"></p>
<p>I made a question about biodegradable plastics.</p>
<p><img alt="Querying the Bagheri article" src="/images/Querying%20Bagheri%2020240316213653.png"></p>
<p>Then I made a question about something that is not mentioned in the article to see what would be the answer.
Surprisingly to me it did not allucinate. It plainly answered that the subject is not discussed in the paper. You can add a large amount of documents. I already tried with markdown files and PDFs, but there a number of file extensions that are supported. Also, the ingested files are kept in place until you delete them. And this deletion is just from the ingested files. It does not mean deleting the original file.</p>
<p><img alt="Querying about foreign subject to the Bagheri article" src="/images/Query%20about%20kraft%20paper%2020240316214244.png"></p>
<h1 id="conclusion">Conclusion</h1>
<p>This is a simple setup of a private and open source LLM. I tried other ones, using AnythingLLM and it didn&rsquo;t work, or it needed workarounds that I don&rsquo;t have the time for. This was the easiest project to set up and there is a lot more that can be done with it. For me, the integration with my Obsidian notes is the next thing that I am aiming to explore.</p>
<p>You can reach out to contact me about this or other topics at my email <a href="mailto:lucas.fernandes.df@gmail.com">lucas.fernandes.df@gmail.com</a>.</p>
<ul class="pa0">
  
   <li class="list di">
     <a href="/tags/ai/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">AI</a>
   </li>
  
   <li class="list di">
     <a href="/tags/rag/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">RAG</a>
   </li>
  
   <li class="list di">
     <a href="/tags/ollama/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Ollama</a>
   </li>
  
   <li class="list di">
     <a href="/tags/mistral/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Mistral</a>
   </li>
  
   <li class="list di">
     <a href="/tags/privategpt/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">PrivateGPT</a>
   </li>
  
   <li class="list di">
     <a href="/tags/m2/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">M2</a>
   </li>
  
   <li class="list di">
     <a href="/tags/macbook-air/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">MacBook-Air</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/post/ai-pin/">Thoughts on the hu.ma.ne AI Pin</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/" >
    &copy;  Lucas F. Aguiar 2024 
  </a>
    <div>
<div class="ananke-socials">
  
    
    <a href="https://linkedin.com/in/lucas-fernandes-aguiar" target="_blank" rel="noopener" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
